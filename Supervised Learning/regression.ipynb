{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dianalves00/6-7-edition/blob/main/Supervised%20Learning/regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKnXBJuyBrA7"
      },
      "source": [
        "# Store Sales - Time Series Forecasting\n",
        "This notebook covers exploratory data analysis (EDA) and feature engineering for the Store Sales dataset.\n",
        "\n",
        "## Dataset Overview\n",
        "- **Goal:** Predict daily store sales.\n",
        "- **Features:** Date, store information, promotions, and more.\n",
        "- **Target:** Sales column.\n",
        "\n",
        "### Exercises:\n",
        "- Conduct EDA to understand trends and relationships.\n",
        "- Engineer meaningful features to improve forecasting accuracy.\n",
        "\n",
        "### Dataset Link:\n",
        "Download the dataset from [Kaggle Store Sales Time Series Forecasting](https://www.kaggle.com/competitions/store-sales-time-series-forecasting/data), from the github repository or use the dataset directly from github."
      ],
      "id": "AKnXBJuyBrA7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmTRkCnOBrA_"
      },
      "source": [
        "## 1. Load and Explore the Data"
      ],
      "id": "ZmTRkCnOBrA_"
    },
    {
      "cell_type": "code",
      "source": [
        "#if you dont have it yet and want to download it and unzip it locally\n",
        "!wget https://github.com/samsung-ai-course/6-7-edition/raw/main/Supervised%20Learning/Datasets/store-sales-time-series-forecasting.zip\n",
        "\n",
        "# 2. Unzip the downloaded file\n",
        "!unzip store-sales-time-series-forecasting.zip -d store_sales_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2yRCt3LnS6Y",
        "outputId": "a63747cf-a68a-45af-c550-21e7a56cbfd8"
      },
      "id": "e2yRCt3LnS6Y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-24 19:25:07--  https://github.com/samsung-ai-course/6-7-edition/raw/main/Supervised%20Learning/Datasets/store-sales-time-series-forecasting.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/samsung-ai-course/6-7-edition/main/Supervised%20Learning/Datasets/store-sales-time-series-forecasting.zip [following]\n",
            "--2024-11-24 19:25:08--  https://raw.githubusercontent.com/samsung-ai-course/6-7-edition/main/Supervised%20Learning/Datasets/store-sales-time-series-forecasting.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22416355 (21M) [application/zip]\n",
            "Saving to: ‘store-sales-time-series-forecasting.zip’\n",
            "\n",
            "store-sales-time-se 100%[===================>]  21.38M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-11-24 19:25:09 (174 MB/s) - ‘store-sales-time-series-forecasting.zip’ saved [22416355/22416355]\n",
            "\n",
            "Archive:  store-sales-time-series-forecasting.zip\n",
            "  inflating: store_sales_data/holidays_events.csv  \n",
            "  inflating: store_sales_data/oil.csv  \n",
            "  inflating: store_sales_data/sample_submission.csv  \n",
            "  inflating: store_sales_data/stores.csv  \n",
            "  inflating: store_sales_data/test.csv  \n",
            "  inflating: store_sales_data/train.csv  \n",
            "  inflating: store_sales_data/transactions.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if you want to unzip programatically (assuming you have the file in this folder on the left)\n",
        "!unzip Supervised\\ Learning/Datasets/store-sales-time-series-forecasting.zip -d Supervised\\ Learning/Datasets/\n"
      ],
      "metadata": {
        "id": "7TgxexkboCJJ"
      },
      "id": "7TgxexkboCJJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f8jPBO3BrBA"
      },
      "execution_count": null,
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "train = pd.read_csv(\"/train.csv\", parse_dates=['date'])\n",
        "stores = pd.read_csv(\"/stores.csv\")\n",
        "oil = pd.read_csv(\"/oil.csv\", parse_dates=['date'])\n",
        "holidays = pd.read_csv(\"/holidays_events.csv\", parse_dates=['date'])\n",
        "\n",
        "# Preview dataset\n",
        "train.head()"
      ],
      "outputs": [],
      "id": "5f8jPBO3BrBA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNj6yQt7BrBB"
      },
      "execution_count": null,
      "source": [
        "# Summary of train dataset\n",
        "train.info()"
      ],
      "outputs": [],
      "id": "MNj6yQt7BrBB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWKZwiYFBrBB"
      },
      "source": [
        "### Question 1: What is the date range of the training data? Use `.min()` and `.max()` on the `date` column."
      ],
      "id": "RWKZwiYFBrBB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnMohKZbBrBC"
      },
      "execution_count": null,
      "source": [
        "# Date range"
      ],
      "outputs": [],
      "id": "qnMohKZbBrBC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpl5HiAIBrBV"
      },
      "source": [
        "## 2. Exploratory Data Analysis"
      ],
      "id": "zpl5HiAIBrBV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn8SV-11BrBV"
      },
      "execution_count": null,
      "source": [
        "# Plot sales over time\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(x='date', y='sales', data=train, ci=None)\n",
        "plt.title('Daily Sales Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Sales')\n",
        "plt.show()"
      ],
      "outputs": [],
      "id": "Wn8SV-11BrBV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltDniUE8BrBW"
      },
      "source": [
        "### Question 2: Are there noticeable trends or seasonality in sales data? What hypotheses can you form based on the plot?"
      ],
      "id": "ltDniUE8BrBW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obrq-GKlBrBW"
      },
      "execution_count": null,
      "source": [
        "# Aggregate sales by year and month\n",
        "train['year'] = train['date'].dt.year\n",
        "train['month'] = train['date'].dt.month\n",
        "monthly_sales = train.groupby(['year', 'month'])['sales'].sum().reset_index()\n",
        "\n",
        "# Plot monthly sales\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(x='month', y='sales', hue='year', data=monthly_sales, marker='o')\n",
        "plt.title('Monthly Sales Trends by Year')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Sales')\n",
        "plt.legend(title='Year')\n",
        "plt.show()"
      ],
      "outputs": [],
      "id": "obrq-GKlBrBW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOA2UAaIBrBW"
      },
      "source": [
        "### Question 3: Which months tend to have higher or lower sales? Can this be linked to holidays or promotions?"
      ],
      "id": "LOA2UAaIBrBW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoVy5m3kBrBW"
      },
      "source": [
        "## 3. Feature Engineering"
      ],
      "id": "QoVy5m3kBrBW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL7jbYsuBrBX"
      },
      "execution_count": null,
      "source": [
        "# Merge train dataset with holidays and oil prices\n",
        "train = train.merge(oil, on='date', how='left')\n",
        "train = train.merge(holidays, on='date', how='left')\n",
        "train = train.merge(stores, on='store_nbr', how='left')\n",
        "\n",
        "# Fill missing oil prices with forward fill\n",
        "train['dcoilwtico'] = train['dcoilwtico'].fillna(method='ffill')\n",
        "#What is this really doing ?\n",
        "\n",
        "# Create new features\n",
        "train['day_of_week'] = #TODO\n",
        "train['is_weekend'] = #TODO\n",
        "train['year_month'] = #TODO OR https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_period.html\n",
        "\n",
        "# Preview engineered features\n",
        "train[['date', 'sales', 'dcoilwtico', 'day_of_week', 'is_weekend']].head()"
      ],
      "outputs": [],
      "id": "lL7jbYsuBrBX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWK0lKXqBrBX"
      },
      "source": [
        "### Question 4: How does oil price (`dcoilwtico`) correlate with sales? Plot and discuss."
      ],
      "id": "gWK0lKXqBrBX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBSU_yyaBrBX"
      },
      "execution_count": null,
      "source": [
        "# Correlation between oil price and sales\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.scatterplot(x='dcoilwtico', y='sales', data=train, alpha=0.5)\n",
        "plt.title('Oil Price vs Sales')\n",
        "plt.xlabel('Oil Price')\n",
        "plt.ylabel('Sales')\n",
        "plt.show()"
      ],
      "outputs": [],
      "id": "CBSU_yyaBrBX"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DFLNSMI9DC2L"
      },
      "id": "DFLNSMI9DC2L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Training Season\n",
        "\n",
        "Based on all the EDA and feature engineer done prior train a simple linear regression"
      ],
      "metadata": {
        "id": "C5jlkUHQDEMM"
      },
      "id": "C5jlkUHQDEMM"
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: ### 4. Training Season\n",
        "# Based on all the EDA and feature engineer done prior train a simple linear regression\n",
        "# import only the necessary and do incompete code\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Select features and target variable\n",
        "features = #TODO\n",
        "target = 'sales'\n",
        "\n",
        "# Handle missing values (if any) -  replace with more robust imputation if necessary\n",
        "train = #TODO\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X = train[features]\n",
        "y = train[target]\n",
        "\n",
        "#Question: In this dataset train and test are already separated. Why would we split it again ? Is there a reason ? Is this correct?\n",
        "#P.s this is a time-series\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = #TODO\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ],
      "metadata": {
        "id": "lb7vlXYtDYJk"
      },
      "id": "lb7vlXYtDYJk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbr9-koqBrBX"
      },
      "source": [
        "## 5. Extra Questions\n",
        "1. Create a lag feature for sales (e.g., `sales_lag_1` for the previous day). How does this improve your understanding of the data?\n",
        "2. Engineer a feature indicating the number of holidays in the past 7 days. Does it help explain sales trends?\n",
        "3. Use one or both of these new features, do they impact the predictions?\n",
        "4. Split the data into training and validation sets for future modeling. How would you ensure no data leakage in a time-series setup? (We will talk about this next, but think about it)"
      ],
      "id": "zbr9-koqBrBX"
    },
    {
      "cell_type": "code",
      "source": [
        "#Have fun ;)"
      ],
      "metadata": {
        "id": "2r3CURGSIrLl"
      },
      "id": "2r3CURGSIrLl",
      "execution_count": null,
      "outputs": []
    }
  ]
}